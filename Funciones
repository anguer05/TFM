****************************************************************************************
*******************   FUNCIONES EMPLEADAS EN R PARA MODELOS  ***************************
****************************************************************************************


****************************************************************************************
***************************   REGRESIÓN LOGÍSTICA  *************************************

cruzadalogistica <- function(data=data,vardep=NULL,
 listconti=NULL,listclass=NULL,grupos=4,sinicio=1234,repe=5)
{
library(dummies)
library(MASS)
library(reshape)
library(caret)
library(dplyr)
library(pROC)
 
  #if  (listclass !=c(""))
  #{
  # for (i in 1:dim(array(listclass))) {
  #  numindi<-which(names(data)==listclass[[i]])
  #  data[,numindi]<-as.character(data[,numindi])
  #  data[,numindi]<-as.factor(data[,numindi])
  # }
  #}   
  
  data[,vardep]<-as.factor(data[,vardep])
  
  # Creo la formula para la logistica
  
  if  (listclass!=c(""))
  {
   koko<-c(listconti,listclass)
  }  else   {
   koko<-c(listconti)
  }
 
  modelo<-paste(koko,sep="",collapse="+")
  formu<-formula(paste(vardep,"~",modelo,sep=""))
  
  formu 
  # Preparo caret   
  
  set.seed(sinicio)
  control<-trainControl(method = "repeatedcv",number=grupos,repeats=repe,
   savePredictions = "all",classProbs=TRUE) 
  
  # Aplico caret y construyo modelo
  
  regresion <- train(formu,data=data,
   trControl=control,method="glm",family = binomial(link="logit"))                  
  preditest<-regresion$pred
  
  preditest$prueba<-strsplit(preditest$Resample,"[.]")
  preditest$Fold <- sapply(preditest$prueba, "[", 1)
  preditest$Rep <- sapply(preditest$prueba, "[", 2)
  preditest$prueba<-NULL
  
  tasafallos<-function(x,y) {
   confu<-confusionMatrix(x,y)
   tasa<-confu[[3]][1]
   return(tasa)
  }
  
  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n
  
  rlog<-preditest %>%
   group_by(Rep) %>%
   summarize(tasa=1-tasafallos(pred,obs))
  
  # CalculamoS AUC  por cada RepeticiÃ³n de cv 
  # Definimnos funciÃ³n
  
  auc<-function(x,y) {
   curvaroc<-roc(response=x,predictor=y)
   auc<-curvaroc$auc
   return(auc)
  }
  

  
  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n
  
  mediasbis<-preditest %>%
   group_by(Rep) %>%
   summarize(auc=auc(obs,Yes))
  
  # Unimos la info de auc y de tasafallos
  
  rlog$auc<-mediasbis$auc
  
  return(rlog)
  
 }
**********************************************************************************************************
**********************************************************************************************************
***************************************** CRUZADA avNNet *************************************************
cruzadaavnnetbin<-function(data=data,vardep="vardep",
  listconti="listconti",listclass="listclass",grupos=4,sinicio=23461,repe=10,
  size="size",decay="decay",repeticiones=5,itera="itera")
 { 
  library(caret)
  # PreparaciÃ³n del archivo
  
  # b)pasar las categÃ³ricas a dummies
  
  if  (listclass!=c(""))
  {
   databis<-data[,c(vardep,listconti,listclass)]
  # databis<- dummy.data.frame(databis, listclass, sep = ".")
  }  else   {
   databis<-data[,c(vardep,listconti)]
  }
  
  # c)estandarizar las variables continuas
  
  # Calculo medias y dtipica de datos y estandarizo (solo las continuas)
  
  means <-apply(data[,listconti],2,mean)
  sds<-sapply(data[,listconti],sd)
  
  # Estandarizo solo las continuas y uno con las categoricas
  
  datacon<-scale(data[,listconti], center = means, scale = sds)
  numerocont<-which(colnames(data)%in%listconti)
  databis<-cbind(datacon,data[,-numerocont,drop=FALSE ])
  
  databis[,vardep]<-as.factor(databis[,vardep])
  
  formu<-formula(paste(vardep,"~.",sep=""))
  
  # Preparo caret   
  
  set.seed(sinicio)
  control<-trainControl(method = "repeatedcv",number=grupos,repeats=repe,
   savePredictions = "all",classProbs=TRUE) 
  
  # Aplico caret y construyo modelo
  
  avnnetgrid <-  expand.grid(size=size,decay=decay,bag=FALSE)
  
  avnnet<- train(formu,data=databis,
   method="avNNet",linout = FALSE,maxit=itera,repeats=repeticiones,
   trControl=control,tuneGrid=avnnetgrid)
  
  print(avnnet$results)
  
  preditest<-avnnet$pred
  
  preditest$prueba<-strsplit(preditest$Resample,"[.]")
  preditest$Fold <- sapply(preditest$prueba, "[", 1)
  preditest$Rep <- sapply(preditest$prueba, "[", 2)
  preditest$prueba<-NULL
  
  tasafallos<-function(x,y) {
   confu<-confusionMatrix(x,y)
   tasa<-confu[[3]][1]
   return(tasa)
  }
  
  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n
  
  red<-preditest %>%
   group_by(Rep) %>%
   summarize(tasa=1-tasafallos(pred,obs))
  
  # CalculamoS AUC  por cada RepeticiÃ³n de cv 
  # Definimnos funciÃ³n
  
  auc<-function(x,y) {
   curvaroc<-roc(response=x,predictor=y)
   auc<-curvaroc$auc
   return(auc)
  }
  
  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n
  
  redbis<-preditest %>%
   group_by(Rep) %>%
   summarize(auc=auc(obs,Yes))
  
  # Unimos la info de auc y de tasafallos
  
  red$auc<-redbis$auc
  
  return(red)
  
 }
**********************************************************************************************************
**********************************************************************************************************
***************************************** RANDOM FOREST  *************************************************
cruzadarfbin<-
 function(data=data,vardep="vardep",
  listconti="listconti",
  listclass="listclass",
  grupos=4,sinicio=23461,repe=10,nodesize=20,
  mtry=2,ntree=50,replace=TRUE,sampsize=400)
 { 
  
  # PreparaciÃ³n del archivo
  
  # b)pasar las categÃ³ricas a dummies
  
  if  (listclass!=c(""))
  {
   databis<-data[,c(vardep,listconti,listclass)]
   databis<- dummy.data.frame(databis, listclass, sep = ".")
   }  
   else   {  
  databis<-data[,c(vardep,listconti)]
   }
  
  # c)estandarizar las variables continuas
  
  # Calculo medias y dtipica de datos y estandarizo (solo las continuas)
  
  means <-apply(data[,listconti],2,mean)
  sds<-sapply(data[,listconti],sd)
  
  # Estandarizo solo las continuas y uno con las categoricas
  
  datacon<-scale(data[,listconti], center = means, scale = sds)
  numerocont<-which(colnames(data)%in%listconti)
  databis<-cbind(datacon,data[,-numerocont,drop=FALSE ])
  
  databis[,vardep]<-as.factor(databis[,vardep])
  
  formu<-formula(paste("factor(",vardep,")~.",sep=""))
  
  # Preparo caret   
  
  set.seed(sinicio)
  control<-trainControl(method = "repeatedcv",number=grupos,repeats=repe,
   savePredictions = "all",classProbs=TRUE) 
  
  # Aplico caret y construyo modelo
  
  rfgrid <-expand.grid(mtry=mtry)
  
  rf<- train(formu,data=databis,
   method="rf",trControl=control,
   tuneGrid=rfgrid,nodesize=nodesize,replace=replace,
   ntree=ntree,sampsize=sampsize)
  
  print(rf$results)
  
  preditest<-rf$pred
  
  preditest$prueba<-strsplit(preditest$Resample,"[.]")
  preditest$Fold <- sapply(preditest$prueba, "[", 1)
  preditest$Rep <- sapply(preditest$prueba, "[", 2)
  preditest$prueba<-NULL
  
  tasafallos<-function(x,y) {
   confu<-confusionMatrix(x,y)
   tasa<-confu[[3]][1]
   return(tasa)
  }
  
  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n
  
  t_forest<-preditest %>%
   group_by(Rep) %>%
   summarize(tasa=1-tasafallos(pred,obs))
  
  # CalculamoS AUC  por cada RepeticiÃ³n de cv 
  # Definimnos funciÃ³n
  
  auc<-function(x,y) {
   curvaroc<-roc(response=x,predictor=y)
   auc<-curvaroc$auc
   return(auc)
  }
  
  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n
  
  forestbis<-preditest %>%
   group_by(Rep) %>%
   summarize(auc=auc(obs,Yes))
  
  # Unimos la info de auc y de tasafallos
  
  t_forest$auc<-forestbis$auc
  
  return(t_forest)
  
 }
 ******************************************************************************************************************
 **********************************   GRADIENT BOOSTING  **********************************************************
 cruzadagbmbin<-
 function(data=data,vardep="vardep",
  listconti="listconti",listclass="listclass",
  grupos=5,sinicio=23461,repe=10,
  n.minobsinnode=20,shrinkage=0.1,n.trees=100,interaction.depth=2)
 { 
  
  # PreparaciÃ³n del archivo
  
  # b)pasar las categÃ³ricas a dummies
  
  if  (listclass!=c(""))
  {
   databis<-data[,c(vardep,listconti,listclass)]
  # databis<- dummy.data.frame(databis, listclass, sep = ".")
  }  else   {
   databis<-data[,c(vardep,listconti)]
  }
  
  # c)estandarizar las variables continuas
  
  # Calculo medias y dtipica de datos y estandarizo (solo las continuas)
  
  means <-apply(data[,listconti],2,mean)
  sds<-sapply(data[,listconti],sd)
  
  # Estandarizo solo las continuas y uno con las categoricas
  
  datacon<-scale(data[,listconti], center = means, scale = sds)
  numerocont<-which(colnames(data)%in%listconti)
  databis<-cbind(datacon,data[,-numerocont,drop=FALSE ])
  
  databis[,vardep]<-as.factor(databis[,vardep])
  
  formu<-formula(paste("factor(",vardep,")~.",sep=""))
  
  # Preparo caret   
  
  set.seed(sinicio)
  control<-trainControl(method = "repeatedcv",number=grupos,repeats=repe,
   savePredictions = "all",classProbs=TRUE) 
  
  # Aplico caret y construyo modelo
  
  
  
   gbmgrid <-expand.grid(n.minobsinnode=n.minobsinnode,
    shrinkage=shrinkage,n.trees=n.trees,
    interaction.depth=interaction.depth)
  
  gbm<- train(formu,data=databis,
   method="gbm",trControl=control,
   tuneGrid=gbmgrid,distribution="bernoulli",verbose=FALSE)
  
  print(gbm$results)
  
  preditest<-gbm$pred
  
  
  preditest$prueba<-strsplit(preditest$Resample,"[.]")
  preditest$Fold <- sapply(preditest$prueba, "[", 1)
  preditest$Rep <- sapply(preditest$prueba, "[", 2)
  preditest$prueba<-NULL
  
  tasafallos<-function(x,y) {
   confu<-confusionMatrix(x,y)
   tasa<-confu[[3]][1]
   return(tasa)
  }
  
  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n
  
  t_boost<-preditest %>%
   group_by(Rep) %>%
   summarize(tasa=1-tasafallos(pred,obs))
  
  # CalculamoS AUC  por cada RepeticiÃ³n de cv 
  # Definimnos funciÃ³n
  
  auc<-function(x,y) {
   curvaroc<-roc(response=x,predictor=y)
   auc<-curvaroc$auc
   return(auc)
  }
  
  # Aplicamos funciÃ³n sobre cada RepeticiÃ³n
  
  boostbis<-preditest %>%
   group_by(Rep) %>%
   summarize(auc=auc(obs,Yes))
  
  # Unimos la info de auc y de tasafallos
  
  t_boost$auc<-boostbis$auc
  
  return(t_boost)
  
 }
 
*******************************************************************************************************************
**************************************************   XGB   *********************************************************
 
 cruzadaxgbmbin<-
  function(data=data,vardep="vardep",
           listconti="listconti",listclass="listclass",
           grupos=5,sinicio=1234,repe=10,
           min_child_weight=20,eta=0.1,nrounds=100,max_depth=2,
           gamma=0,colsample_bytree=1,subsample=1,alpha=0,lambda=0,lambda_bias=0)
  { 
    
    # PreparaciÃ³n del archivo
    
    # b)pasar las categÃ³ricas a dummies
    
    if  (listclass!=c(""))
    {
      databis<-data[,c(vardep,listconti,listclass)]
      #databis<- dummy.data.frame(databis, listclass, sep = ".")
    }  else   {
      databis<-data[,c(vardep,listconti)]
    }
    
    # c)estandarizar las variables continuas
    
    # Calculo medias y dtipica de datos y estandarizo (solo las continuas)
    
    means <-apply(databis[,listconti],2,mean)
    sds<-sapply(databis[,listconti],sd)
    
    # Estandarizo solo las continuas y uno con las categoricas
    
    datacon<-scale(databis[,listconti], center = means, scale = sds)
    numerocont<-which(colnames(databis)%in%listconti)
    databis<-cbind(datacon,databis[,-numerocont,drop=FALSE ])
    
    databis[,vardep]<-as.factor(databis[,vardep])
    
    formu<-formula(paste("factor(",vardep,")~.",sep=""))
    
    # Preparo caret   
    
    set.seed(sinicio)
    control<-trainControl(method = "repeatedcv",number=grupos,repeats=repe,
                          savePredictions = "all",classProbs=TRUE) 
    
    # Aplico caret y construyo modelo
    
    xgbmgrid <-expand.grid( min_child_weight=min_child_weight,
                            eta=eta,nrounds=nrounds,max_depth=max_depth,
                            gamma=gamma,colsample_bytree=colsample_bytree,subsample=subsample)
    
    xgbm<- train(formu,data=databis,
                 method="xgbTree",trControl=control,
                 tuneGrid=xgbmgrid,objective = "binary:logistic",verbose=FALSE,
                 alpha=alpha,lambda=lambda,lambda_bias=lambda_bias)
    
    print(xgbm$results)
    
    preditest<-xgbm$pred
    
    
    preditest$prueba<-strsplit(preditest$Resample,"[.]")
    preditest$Fold <- sapply(preditest$prueba, "[", 1)
    preditest$Rep <- sapply(preditest$prueba, "[", 2)
    preditest$prueba<-NULL
    
    
    tasafallos<-function(x,y) {
      confu<-confusionMatrix(x,y)
      tasa<-confu[[3]][1]
      return(tasa)
    }
    
    # Aplicamos funciÃ³n sobre cada RepeticiÃ³n
    
    xboost<-preditest %>%
      group_by(Rep) %>%
      summarize(tasa=1-tasafallos(pred,obs))
    
    # CalculamoS AUC  por cada RepeticiÃ³n de cv 
    # Definimnos funciÃ³n
    
    auc<-function(x,y) {
      curvaroc<-roc(response=x,predictor=y)
      auc<-curvaroc$auc
      return(auc)
    }
    
    # Aplicamos funciÃ³n sobre cada RepeticiÃ³n
    
    mediasbis<-preditest %>%
      group_by(Rep) %>%
      summarize(auc=auc(obs,Yes))
    
    # Unimos la info de auc y de tasafallos
    
    xboost$auc<-mediasbis$auc
    
    #return(xboost)
    return(list(xboost,preditest))
  }

 
 
